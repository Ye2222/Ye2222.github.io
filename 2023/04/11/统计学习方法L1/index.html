<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico">
  <link rel="mask-icon" href="/images/favicon.ico" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-flat-top.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"ye2222.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="1.1 统计学习">
<meta property="og:type" content="article">
<meta property="og:title" content="统计学习方法L1">
<meta property="og:url" content="https://ye2222.github.io/2023/04/11/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95L1/index.html">
<meta property="og:site_name" content="Yeの博客">
<meta property="og:description" content="1.1 统计学习">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/UPDF_Uxe1lm0AqM.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/UPDF_KCLFSY29rZ.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/UPDF_rukv9K8KNy.png">
<meta property="article:published_time" content="2023-04-11T07:56:41.000Z">
<meta property="article:modified_time" content="2023-04-15T02:21:12.341Z">
<meta property="article:author" content="GuoYB">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/UPDF_Uxe1lm0AqM.png">

<link rel="canonical" href="https://ye2222.github.io/2023/04/11/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95L1/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>统计学习方法L1 | Yeの博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <!-- <div class="headband"></div> -->
    <a target="_blank" rel="noopener" href="https://github.com/Ye2222" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Yeの博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">记录生活中的点点滴滴</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">9</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">30</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">103</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://ye2222.github.io/2023/04/11/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95L1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar1.gif">
      <meta itemprop="name" content="GuoYB">
      <meta itemprop="description" content="欢迎欢迎">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yeの博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          统计学习方法L1
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-04-11 15:56:41" itemprop="dateCreated datePublished" datetime="2023-04-11T15:56:41+08:00">2023-04-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-04-15 10:21:12" itemprop="dateModified" datetime="2023-04-15T10:21:12+08:00">2023-04-15</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">统计学习方法</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
            <div class="post-description">1.1 统计学习</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <blockquote>
<p>第一章的主要内容</p>
<ol>
<li>叙述统计学习的定义、研究对象和方法</li>
<li>叙述监督学习（本书的主要内容）</li>
<li>提出统计学习方法的三要素：模型、策略和算法</li>
<li>介绍模型选择，包括正则化、交叉验证与学习的泛化能力</li>
<li>介绍生成模型与判别模型</li>
<li>介绍监督学习方法的应用：分类问题、标注问题与回归问题</li>
</ol>
</blockquote>
<h2><span id="11-统计学习">1.1 统计学习</span></h2><h3><span id="统计学习的特点">统计学习的特点</span></h3><ul>
<li>定义：<strong>统计学习（statistical learning）</strong>是关于计算机<strong>基于数据构建概率统计模型</strong>并<strong>运</strong><br><strong>用模型对数据进行预测与分析</strong>的一门学科．统计学习也称为<strong>统计机器学习</strong><br>(statistical machine learning）</li>
<li>主要特点：<ul>
<li>统计学习<strong>以计算机及网络为平台</strong>，是建立在计算机及网络之上的</li>
<li>统计学习<strong>以数据为研究对象</strong>，是数据驱动的学科</li>
<li>统计学习的目的是<strong>对数据进行预测与分析</strong></li>
<li>统计学习<strong>以方法为中心</strong>，统计学习方法<strong>构建模型并应用模型进行预测与分析</strong></li>
<li>统计学习是概率论、统计学、信息论、计算理论、最优化理论及计算机科学等多个领域的交叉学科，并且在发展中逐步形成独自的理论体系与方法论．</li>
</ul>
</li>
</ul>
<blockquote>
<p>统计学习就是计算机系统通过运用数据及统计方法提高系统性能的机器学习. </p>
<p>现在，当人们提及机器学习时，往往是指统计机器学习． </p>
</blockquote>
<h3><span id="统计学习的对象">统计学习的对象</span></h3><ul>
<li>很明显是<u>数据</u>，<strong>从数据出发，提取数据的特征，抽象出数据的模型，发现数据中的知识，又回到对数据的分析与预测中去</strong></li>
<li>数据是<strong>多样的</strong>，包括存在于计算机及网络上的各种数字、文字、图像、视频、音频数据以及它们的组合．</li>
<li><strong>统计学习的前提</strong>：同类数据具有一定的统计规律性，这里的同类数据是指具有某种共同性质的数据<ul>
<li>由于具有统计规律性，所以可以用概率统计方法来加以处理。</li>
<li>比如，可以用随机变量描述数据中的特征，用概率分布描述数据的统计规律。</li>
</ul>
</li>
</ul>
<h3><span id="统计学习的目的">统计学习的目的</span></h3><ul>
<li>目的：用于对数据进行预测与分析，特别是对未知的新数据进行预测与分析</li>
<li>对数据的预测与分析是通过构建概率统计模型实现的</li>
<li>总的目标：考虑学习什么样的模型和如何学习模型，以使模型能对数据进行准确的预测与分析，同时也要考虑尽可能地提高学习效率</li>
</ul>
<h3><span id="统计学习的方法">统计学习的方法</span></h3><ul>
<li>基于数据构建统计模型从而对数据进行预测与分析。</li>
<li>组成<ul>
<li>监督学习（supervised learning）</li>
<li>非监督学习（unsupervised learning）</li>
<li>半监督学习（semi-supervised learning）</li>
<li>强化学习（reinforcement learning）</li>
</ul>
</li>
<li>主要讨论监督学习，这种情况下的统计学习的方法概括如下：<ul>
<li>从给定的、有限的、用于学习的<strong>训练数据（training data）</strong>集合出发，假设数据是独立同分布产生的</li>
<li>并且假设要学习的模型属于某个函数的集合，称为<strong>假设空间（hypothesis space）</strong></li>
<li>应用某个<strong>评价准则（evaluation criterion）</strong>，从假设空间中选取一个最优的模型，使它对已知训练数据及未知测试数据<strong>（test data）</strong>在给定的评价准则下有最优的预测</li>
<li>最优模型的选取由算法实现</li>
</ul>
</li>
<li>统计学习方法包括<strong>模型的假设空间、模型选择的准则以及模型学习的算法</strong></li>
<li><p>这个过程概括为三要素</p>
<ul>
<li>模型（model）</li>
<li>策略（strategy）</li>
<li>算法（algorithm）</li>
</ul>
</li>
<li><p>实现统计学习方法的步骤如下： </p>
<p>（1）得到一个有限的训练数据集合； </p>
<p>（2）确定包含所有可能的模型的假设空间，即学习模型的集合； </p>
<p>（3）确定模型选择的准则，即学习的策略； </p>
<p>（4）实现求解最优模型的算法，即学习的算法； </p>
<p>（5）通过学习方法选择最优模型； </p>
<p>（6）利用学习的最优模型对新数据进行预测或分析</p>
</li>
</ul>
<h3><span id="统计学习的研究">统计学习的研究</span></h3><ul>
<li>包括三个方面<ul>
<li>统计学习方法（statistical learning method）<ul>
<li>旨在开发新的学习方法</li>
</ul>
</li>
<li>统计学习理论（statistical learning theory）<ul>
<li>研究在于探求统计学习方法的有效性与效率，以及统计学习的基本理论问题</li>
</ul>
</li>
<li>统计学习应用（application of statistical learning）<ul>
<li>主要考虑将统计学习方法应用到时机问题中取，解决实际问题</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2><span id="12-监督学习">1.2 监督学习</span></h2><p>监督学习的任务：学习一个模型，使模型能够对任意给定的输入，对其相应的输出做出一个好的预测</p>
<h3><span id="基本概念">基本概念</span></h3><h4><span id="输入空间-特征空间与输出空间">输入空间、特征空间与输出空间</span></h4><ul>
<li><p>将输入与输出所有可能取值的集合分别称为<strong>输入空间（input space）与输出空间（output space）</strong></p>
<ul>
<li>输入与输出空间可以是有限元素的集合，也可以是整个欧氏空间</li>
<li>输入空间与输出空间可以是同一个空间，也可以是不同的空间；</li>
<li>但通常输出空间远远小于输入空间．</li>
</ul>
</li>
<li><p>每个具体的输入是一个<strong>实例（instance）</strong>，通常由<strong>特征向量（feature vector）</strong>表示</p>
</li>
<li><p>所有特征向量存在的空间称为<strong>特征空间（feature space）</strong>，特征空间的每一维对应于一个特征</p>
<ul>
<li>有时假设输入空间与特征空间为相同的空间，对它们不予区分</li>
<li>有时假设输入空间与特征空间为不同的空间，将实例从输入空间映射到特征空间</li>
<li>模型实际上都是定义在特征空间上的</li>
</ul>
</li>
<li><p>在监督学习过程中，将输入与输出看做是<strong>定义在输入（特征）空间与输出空间上的随机变量的取值</strong></p>
<ul>
<li>监督学习从<strong>训练数据（training data）</strong>集合中学习模型，对<strong>测试数据（test data）</strong>进行预测</li>
<li>训练数据由输入（或特征向量）与输出对组成，通常表示为</li>
</ul>
<script type="math/tex; mode=display">
T = \{(x_1, y_1), (x_2, y_2), \dots , (x_N, y_N)\}</script><ul>
<li>测试数据由相应的输入与输出对组成。</li>
<li>输入与输出对又称为<strong>样本（sample）</strong>或样本点</li>
</ul>
</li>
<li><p>输入变量X和输出变量Y有不同的类型，可以是连续的，也可以是离散的</p>
<ul>
<li>输入变量与输出变量均为连续变量的预测问题称为<strong>回归问题</strong></li>
<li>输出变量为有限个离散变量的预测问题称为<strong>分类问题</strong></li>
<li>输入变量与输出变量序列的预测问题称为<strong>标注问题</strong></li>
</ul>
</li>
</ul>
<h4><span id="联合概率分布">联合概率分布</span></h4><ul>
<li><p>监督学习假设输入与输出的随机变量<em>X</em>和<em>Y</em>遵循联合概率分布<em>P(X, Y)</em></p>
<ul>
<li>$P(X, \ Y)$表示分布函数，或者分布密度函数</li>
</ul>
<blockquote>
<p>注意：在学习过程中，假定这一联合概率分布存在，训练数据与测试数据被看作是依联合概率分布$P(X, \ Y)$独立同分布产生的。</p>
</blockquote>
</li>
<li><p>统计学习假设数据存在一定的统计规律，X 和Y 具有联合概率分布的假设就是监督学习关于<br>数据的基本假设． </p>
</li>
</ul>
<h4><span id="假设空间">假设空间</span></h4><ul>
<li>监督学习目的在于学习<strong>一个由输入到输出的映射</strong>，这一映射由<strong>模型</strong>来表示</li>
<li>模型属于由输入空间到输出空间的映射的集合，该集合就是<strong>假设空间（hypothesis space）</strong><ul>
<li>假设空间的确定意味着学习范围的确定</li>
</ul>
</li>
<li>监督学习的模型可以是概率模型或非概率模型，由条件概率分布$P(Y|X)$或决策函数（decision function）$Y = f(X)$表示，随具体学习方法而定。<ul>
<li>对具体的输入进行相应的输出预测时，写作$P(y|x)$或$y = f(x)$</li>
</ul>
</li>
</ul>
<h3><span id="问题的形式化">问题的形式化</span></h3><ul>
<li>监督学习利用训练数据集学习一个模型，再用模型对测试样本集进行<strong>预测（prediction）</strong></li>
<li>这个过程中需要训练数据集，而训练数据集往往是人工给出的，称为监督学习<ul>
<li>监督学习分为学习和预测两个阶段，由学习系统与预测系统完成</li>
</ul>
</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/UPDF_Uxe1lm0AqM.png" alt="UPDF_Uxe1lm0AqM"></p>
<p>如果这个模型有很好的预测能力，训练样本输出$y_i$和模型输出$f(x_i)$之间的差就应该足够小．学习系统通过不断的尝试，选取最好的模型，以便对训练数据集有足够好的预测，同时对未知的测试数据集的预测也有尽可能好的推广． </p>
<h2><span id="13-统计学习三要素">1.3 统计学习三要素</span></h2><blockquote>
<p>方法 = 模型 + 策略 + 算法</p>
</blockquote>
<h3><span id="模型">模型</span></h3><ul>
<li><p>在监督学习过程中，模型就是所要学习的条件概率分布或决策函数</p>
</li>
<li><p>模型的<strong>假设空间（hypothesis space）</strong>包含所有可能的条件概率分布或决策函数</p>
<ul>
<li>例如，假设决策函数是输入变量的线性函数，那么模型的假设空间就是所有这些线性函数构成的函数集合</li>
</ul>
</li>
</ul>
<hr>
<p>假设空间用$F$表示，假设空间可以定义为<strong>决策函数的集合</strong></p>
<script type="math/tex; mode=display">
F = \{f \ | \ Y \ = \ f(X) \}</script><p>其中，$X$和$Y$是定义在输入空间和输出空间上的变量</p>
<ul>
<li>这时$F$通常是由一个参数向量决定的函数族</li>
</ul>
<script type="math/tex; mode=display">
F = \{f \ | \ Y \ = \ f_{\theta}(X), \ \theta \ \in \ R^n \}</script><p>参数向量$\theta$取值于$n$维欧式空间$R^n$，称为<strong>参数空间（parameter space）</strong></p>
<hr>
<p>假设空间也可以定义为<strong>条件概率的集合</strong></p>
<script type="math/tex; mode=display">
F = \{ P \ | \ P(Y | X) \}</script><p>其中，$X$和$Y$是定义在输入空间和输出空间上的随机变量</p>
<ul>
<li>这时$F$通常是由一个参数向量决定的条件概率分布族</li>
</ul>
<script type="math/tex; mode=display">
F = \{P \ | \ P_{\theta}(Y |X), \theta \in R^n \}</script><p>参数向量$\theta$取值于$n$维欧式空间$R^n$，称为参数空间（parameter space）</p>
<blockquote>
<p>本书称由决策函数表示的模型为非概率模型，由条件概率表示的模型为概率模型</p>
</blockquote>
<h3><span id="策略">策略</span></h3><p>有了模型的假设空间，统计学习接着要考虑的是按照什么样的准则学习或选择最优的模型</p>
<ul>
<li>统计学习的目标在于从假设空间中选取最优模型</li>
</ul>
<h4><span id="损失函数和风险函数">损失函数和风险函数</span></h4><ul>
<li>损失函数度量<strong>模型一次预测的好坏</strong></li>
<li>风险函数度量<strong>平均意义下模型预测的好坏</strong></li>
</ul>
<p><strong>损失函数</strong>是$f(X)$和$Y$的非负实值函数，记作$L(Y, \ f(X))$</p>
<ul>
<li><p>常用的损失函数</p>
<ul>
<li>0-1损失函数（0-1 loss function）</li>
</ul>
<script type="math/tex; mode=display">
\begin{align*}
\begin{split}
L(Y, f(X))= \left \{
\begin{array}{ll}
    1, & Y \ne \ f(X)         \\
    0, & Y = f(X)             \\ 
\end{array}
\right.
\end{split}
\end{align*}</script><ul>
<li>平方损失函数（quadratic loss function）</li>
</ul>
<script type="math/tex; mode=display">
L(Y, f(X)) = (Y\ - \ f(X))^2</script><ul>
<li>绝对损失函数（absolute loss function）</li>
</ul>
<script type="math/tex; mode=display">
L(Y, f(X)) = |Y \ - \ f(X)|</script><ul>
<li>对数损失函数（logarithmic loss function）或对数似然损失函数（loglikelihood loss function）</li>
</ul>
<script type="math/tex; mode=display">
L(Y, P(Y|X)) = -logP(Y|X)</script></li>
<li><p>损失函数值越小，模型就越好</p>
</li>
<li><p>由于模型的输入、输出$（X,Y）$是随机变量，遵循联合分布$P(X, Y)$，所以损失函数的期望是</p>
</li>
</ul>
<script type="math/tex; mode=display">
R_{exp}(f) = E_p[L(Y, f(X))] = \int_{X \times Y}L(y, f(x))P(x, y)dxdy</script><p>这是理论上模型$f(X)$关于联合分布$P(X,Y)$的平均意义下的损失，成为<strong>风险函数（risk function）或期望损失（expected loss）</strong></p>
<ul>
<li>学习的目标就是选择期望风险最小的模型<ul>
<li>由于联合分布$P(X,Y)$是未知的，$R_{exp}(f)$不能直接计算</li>
<li>这样一来，一方面根据期望风险最小学习模型要用到联合分布，另一方面联合分布又是未知的，所以监督学习就成为一个<strong>病态问题（ill-formed problem）</strong></li>
</ul>
</li>
<li>给定一个训练数据集</li>
</ul>
<script type="math/tex; mode=display">
T = \{(x_1, y_1), (x_2, y_2), \dots , (x_N, y_N)\}</script><p>模型$f(X)$关于训练数据集的平均损失称为<strong>经验风险（empirical risk）</strong>或<strong>经验损失(empirical loss)</strong>，记作$R_{emp}$</p>
<script type="math/tex; mode=display">
R_{emp}(f) = \frac{1}{N} \sum_{i=1} ^NL(y_i,f(x_i))</script><blockquote>
<p>期望风险和经验风险的区别</p>
<ul>
<li>期望风险$R_{exp}(f)$是模型关于联合分布的期望损失</li>
<li>经验风险$R_{emp}(f)$是模型关于训练样本集的平均损失</li>
</ul>
</blockquote>
<ul>
<li>根据大数定律，当样本容量$N$趋于无穷时，经验风险$R_{emp}(f)$趋于期望风险$R_{exp}(f)$，所以很自然地想到用经验风险估计期望风险。</li>
<li>但是现实中训练样本数目有限，甚至很小，所以这么做往往并不理想</li>
<li>要对经验风险进行一定的矫正，这就关系到监督学习的两个基本策略：经验风险最小化和结构风险最小化</li>
</ul>
<h4><span id="经验风险最小化与结构风险最小化">经验风险最小化与结构风险最小化</span></h4><p>在假设空间、损失函数以及训练数据集确定的情况下，经验风险函数式就可以确定</p>
<h4><span id="经验风险最小化empirical-risk-minimizationerm">经验风险最小化（empirical risk minimization，ERM）</span></h4><ul>
<li>该策略认为，经验风险最小的模型就是最优的模型</li>
<li>根据该策略，按照经验风险最小化来求最优模型就是求解最优化问题</li>
</ul>
<script type="math/tex; mode=display">
\min_{f \in F} \frac{1}{N}\sum^N_{i=1}L(y_i, f(x_i))</script><p>其中，$F$是假设空间</p>
<ul>
<li>当样本容量足够大时，经验风险最小化能保证有很好的学习效果，在现实中被广泛采用<ul>
<li>如，<strong>极大似然估计（maximum likelihood estimation）</strong>就是经验风险最小化的一个例子，当模型是条件概率分布，损失函数是对数损失函数时，经验风险最小化就等价于极大似然估计</li>
<li>但是，当样本容量很小，经验风险最小化学习的效果未必很好，会产生“过拟合”现象</li>
</ul>
</li>
</ul>
<h4><span id="结构风险最小化structural-risk-minimizationsrm">结构风险最小化（structural risk minimization，SRM）</span></h4><ul>
<li>为了防止过拟合而提出来的策略</li>
<li>结构风险最小化等价于<strong>正则化（rugularization）</strong></li>
<li>结构风险在经验风险上加上表示<strong>模型复杂度</strong>的<strong>正则化项（regularizer）或罚项（penalty term）</strong></li>
</ul>
<script type="math/tex; mode=display">
R_{srm}(f) = \frac{1}{N}\sum^N_{i=1}L(y_i,f(x_i)) + \lambda J(f)</script><p>其中$J(f)$为模型的复杂度，是定义在假设空间$F$上的泛函</p>
<ul>
<li>模型$f$越复杂，复杂度$J(f)$就越大，反之则相反<ul>
<li>也就是说，复杂度表示了对复杂模型的惩罚</li>
</ul>
</li>
<li>$\lambda \ge 0$是系数，用来权衡经验风险和模型复杂度</li>
<li>结构风险小需要经验风险与模型复杂度同时小<ul>
<li>比如，贝叶斯估计中的最大后验概率估计（maximum posterior probability estimation, MAP）就是一个结构风险最小化的一个例子。</li>
<li>当模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示时，结构风险最小化就等价于最大后验概率估计． </li>
</ul>
</li>
<li>结构风险最小化的策略认为结构风险最小的模型是最优的模型，求最优模型就是求解最优化问题</li>
</ul>
<script type="math/tex; mode=display">
\min_{f \in F} \frac{1}{N}\sum_{i=1}^NL(y_i,f(x_i)) + \lambda J(f)</script><p>监督学习问题就变成了经验风险或结构风险函数的最优化问题．这时经验或结构风险函数是最优化的目标函数</p>
<h3><span id="算法">算法</span></h3><blockquote>
<p>算法是指学习模型的具体计算方法</p>
</blockquote>
<ul>
<li>统计学习基于训练数据集，根据学习策略，从假设空间中选择最优模型，最后需要考虑用什么样的计算方法求解最优模型</li>
<li>统计学习方法就归结为最优化问题，统计学习的算法成为求解最优化问题的算法<ul>
<li>如果最优化问题有显式的解析解，最优化问题就很简单，但通常解析解不存在</li>
<li>这就需要数值计算的方法求解，如何保证找到全局最优解，并使求解的过程非常高效，成为一个重要问题</li>
</ul>
</li>
<li>统计学习可利用已有的最优化算法，有时也需要开发独立的最优化算法</li>
</ul>
<p>统计学习方法之间的不同，主要来自其模型、策略、算法的不同．确定了模型、策略、算法，统计学习的方法也就确定了．这也就是将其称为统计学习三要素的原因．</p>
<h2><span id="14-模型评估与模型选择">1.4 模型评估与模型选择</span></h2><h3><span id="训练误差与测试误差">训练误差与测试误差</span></h3><ul>
<li>当损失函数给定时，基于损失函数的模型的<strong>训练误差（training error）</strong>和模型的<strong>测试误差（test error）</strong>就自然成为学习方法评估的标准．</li>
</ul>
<blockquote>
<p>注意，统计学习方法具体采用的损失函数未必是评估时使用的损失函数．</p>
<p>当然，让两者一致是比较理想的</p>
</blockquote>
<ul>
<li>假设学习到的模型是$Y = \hat{f}(X)$，训练误差是模型关于训练数据集的平均损失</li>
</ul>
<script type="math/tex; mode=display">
R_{emp}(\hat{f}) = \frac{1}{N}\sum^N_{i=1}L(y_i, \hat{f}(x_i))</script><p>其中，$N$是训练样本容量</p>
<ul>
<li>测试误差是模型关于测试数据集的平均损失</li>
</ul>
<script type="math/tex; mode=display">
e_{test} = \frac{1}{N} \sum^{N^{`}}_{i=1}L(y_i, \hat{f}(x_i))</script><p>其中，$N^`$是测试样本容量</p>
<ul>
<li>当损失函数是0-1损失时，测试误差就变成了常见的测试数据集上的误差率(error rate)了</li>
<li>训练误差的大小，对判断给定问题是不是一个容易学习的问题是有意义的，但本质上不重要</li>
<li>测试误差反映了学习方法对未知的测试数据集的预测能力，是学习中的重要概念<ul>
<li>通常将学习方法对未知数据的预测能力称为<strong>泛化能力（generalization ability）</strong></li>
</ul>
</li>
</ul>
<h3><span id="过拟合与模型选择">过拟合与模型选择</span></h3><ul>
<li>当假设空间含有不同复杂度（例如，不同的参数个数）的模型时，就要面临<strong>模型选择（model selection）</strong>的问题</li>
<li>如果在假设空间中存在“真”模型，那么所选择的模型应该逼近真模型<ul>
<li>具体地，所选择的模型要与真模型的参数个数相同，参数向量与真模型的参数向量相近</li>
</ul>
</li>
<li>但是，如果</li>
<li>一味追求提高对训练数据的预测能力，所选模型的复杂度则往往会比真模型更高，这种现象成为<strong>过拟合（over-fitting）</strong><ul>
<li>过拟合是指学习时选择的模型所包含的参数过多，以致于出现这一模型对已知数据预测得很好，但对未知数据预测得很差的现象．</li>
</ul>
</li>
<li>模型选择旨在避免过拟合并提高模型的预测能力</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/UPDF_KCLFSY29rZ.png" alt="UPDF_KCLFSY29rZ" style="zoom:67%;"></p>
<h2><span id="15-正则化与交叉验证">1.5 正则化与交叉验证</span></h2><h3><span id="正则化regularization">正则化（regularization）</span></h3><ul>
<li>正则化是结构风险最小化策略的实现，是在经验风险上加一个<strong>正则化项（regularizer）或罚项（penalty term）</strong></li>
<li>正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大<ul>
<li>比如，正则化项可以是模型参数向量的范数</li>
</ul>
</li>
<li>正则化一般具有如下形式</li>
</ul>
<script type="math/tex; mode=display">
\min_{f \in F} \frac{1}{N}\sum_{i=1}^N L(y_i, f(x_i)) +\lambda J(f)</script><p>其中，第1项是经验风险，第2项是正则化项，$\lambda \ge 0$为调整两者之间关系的系数</p>
<ul>
<li><p>正则化项可以取不同的形式</p>
</li>
<li><p>例如，回归问题，损失函数为平方损失，正则化项可以是参数向量的$L^2$范数</p>
</li>
</ul>
<script type="math/tex; mode=display">
L(w) = \frac{1}{N}\sum_{i=1}^N(f(x_i;w)-y_i)^2 + \frac{\lambda}{2} ||w||^2</script><p>也可以是参数向量的$L_1$范数</p>
<script type="math/tex; mode=display">
L(w) = \frac{1}{N}\sum_{i=1}^N(f(x_i;w)-y_i)^2 + \lambda ||w||_1</script><ul>
<li>正则化符合<strong>奥卡姆剃刀(Occam’s razor)原理</strong>．奥卡姆剃刀原理应用于模型选择时变为以下想法：在所有可能选择的模型中，能够很好地解释已知数据并且十分简单才是最好的模型，也就是应该选择的模型</li>
<li>从<strong>贝叶斯估计</strong>的角度来看，正则化项对应于模型的先验概率．可以假设复杂的模型有较小的先验概率，简单的模型有较大的先验概率． </li>
</ul>
<h3><span id="交叉验证cross-validation">交叉验证（cross validation）</span></h3><ul>
<li><p>给定的样本数据充足，可随机地将数据集切分成三部分，分别为训练集（training set）、验证集（validation set）和测试集（test set）</p>
<ul>
<li>训练集（training set）：用来训练模型</li>
<li>验证集（validation set）：用于模型的选择</li>
<li>测试集（test set）：用于最终对学习方法的评估</li>
</ul>
</li>
<li><p>在学习到的不同复杂度的模型中，选择对验证集有最小预测误差的模型</p>
</li>
<li>由于验证集有足够多的数据，用它对模型进行选择也是有效的</li>
</ul>
<h4><span id="简单交叉验证">简单交叉验证</span></h4><ul>
<li><p>随机地将已给数据分成两部分</p>
<ul>
<li><p>一部分作为训练集</p>
</li>
<li><p>另一部分作为测试集</p>
</li>
<li><p>（例如，70%的数据为训练集，30%的数据为测试集）</p>
</li>
</ul>
</li>
<li><p>用训练集在各种条件下（例如，不同的参数个数）训练模型</p>
</li>
<li>在测试集上评价各个模型的测试误差，选出测试误差最小的模型</li>
</ul>
<h4><span id="s折交叉验证s-fold-cross-validation">S折交叉验证（S-fold cross validation）</span></h4><ul>
<li>首先随机地将已给数据切分为$S$个互不相交的大小相同的子集</li>
<li>然后利用$S-1$个子集的数据训练模型，利用余下的子集测试模型</li>
<li>将这一过程对可能的$S$种选择重复进行</li>
<li>最后选出$S$次评测中平均测试误差最小的模型</li>
</ul>
<h4><span id="留一交叉验证">留一交叉验证</span></h4><ul>
<li>$S$折交叉验证的特殊情形是$S = N$，称为<strong>留一交叉验证（leave-one-out cross validation）</strong></li>
<li>往往在数据缺乏的情况下使用</li>
</ul>
<h2><span id="16-泛化能力">1.6 泛化能力</span></h2><h3><span id="泛化误差">泛化误差</span></h3><blockquote>
<p>学习方法的<strong>泛化能力（generalization ability）</strong>是指由该方法学习到的模型对未知数据的预测能力，是学习方法本质上重要的性质</p>
</blockquote>
<ul>
<li>现实中采用最多的办法是通过<strong>测试误差</strong>来评价学习方法的泛化能力<ul>
<li>这种评价依赖于测试数据集，而测试数据集是有限的，很有可能由此得到的评价结果是不可靠的</li>
<li>统计学习理论试图从理论上对学习方法的泛化能力进行分析</li>
</ul>
</li>
<li>定义：如果学到的模型是$\hat{f}$，那么用这个模型对未知数据预测的误差即为<strong>泛化误差（generalization error）</strong></li>
</ul>
<script type="math/tex; mode=display">
R_{exp}(\hat{f}) = E_p[L(Y,\hat{f}(X))] = \int_{X \times Y}L(y,\hat{f}(x))P(x,y)dxdy</script><ul>
<li>泛化误差反映了学习方法的泛化能力，如果一种方法学习到的模型比另一种方法学习的模型具有更小的泛化误差，则该方法更有效<ul>
<li>事实上，泛化误差就是所学习到的模型的期望风险</li>
</ul>
</li>
</ul>
<h3><span id="泛化误差上界">泛化误差上界</span></h3><blockquote>
<p>学习方法的泛化能力分析往往是通过研究泛化误差的概率上界进行的，简称为<strong>泛化误差上界（generalization error bound）</strong></p>
</blockquote>
<ul>
<li><p>具体来说，就是通过比较两种学习方法的泛化误差上界的大小来比较它们的优劣</p>
</li>
<li><p>有以下性质</p>
<ul>
<li>是样本容量的函数，当样本容量增加时，泛化上界趋于0</li>
<li>是假设空间容量的函数，假设空间容量越大，模型就越难学，泛化误差上界就越大</li>
</ul>
</li>
</ul>
<h2><span id="17-生成模型与判别模型">1.7 生成模型与判别模型</span></h2><p>监督学习方法可以分为<strong>生成方法（generative approach）和判别方法（discriminative approach）</strong>，所学到的模型分别成为<strong>生成模型（generative model）和判别模型（discriminative model）</strong></p>
<h3><span id="生成模型">生成模型</span></h3><ul>
<li>生成方法由数据学习联合概率分布$P(X,Y)$，然后求出条件概率分布$P(Y|X)$作为预测的模型，即生成模型</li>
</ul>
<script type="math/tex; mode=display">
P(Y|X)  = \frac{P(X, Y)}{P(X)}</script><p>之所以被称为生成方法，是因为模型表示了给定输入$X$产生输出$Y$的生成关系</p>
<ul>
<li>典型的生成模型：朴素贝叶斯法和隐马尔科夫模型</li>
</ul>
<h3><span id="判别模型">判别模型</span></h3><ul>
<li><p>判别方法由数据直接学习决策函数$f(X)$或者条件概率分布$P(Y|X)$作为预测的模型，即判别模型</p>
</li>
<li><p>判别方法关心的是对给定的输入$X$，应该预测什么样的输出$Y$</p>
</li>
<li>典型的判别模型：k近邻法、感知机、决策树、逻辑斯蒂回归模型、最大熵模型、支持向量机、提升方法和条件随机场</li>
</ul>
<h3><span id="比较">比较</span></h3><ul>
<li>生成方法和判别方法各有优缺点，适用于不同条件下的学习方法</li>
<li>生成方法的特点：<ul>
<li>生成方法可以<strong>还原出联合概率分布</strong>$P(X,Y)$，而判别方法不能</li>
<li>生成方法的<strong>学习收敛速度更快</strong>，即当样本容量增加的时候，学到的模型可以更快地收敛于真实模型</li>
<li>存在隐变量时，仍可以用生成方法学习</li>
</ul>
</li>
<li>判别方法的特点：<ul>
<li>判别方法<strong>直接学习的是条件概率$P(Y|X)$或决策函数$f(X)$</strong>，直接进行预测，往往学习的准确率更高</li>
<li>由于直接学习$P(Y|X)$或$f(X)$，可以<strong>对数据进行各种程度上的抽象、定义特征并使用特征</strong>，可以简化学习问题</li>
</ul>
</li>
</ul>
<h2><span id="18-分类问题">1.8 分类问题</span></h2><blockquote>
<p>分类是监督学习的一个核心问题</p>
</blockquote>
<ul>
<li>当<strong>输出变量$Y$取有限个离散值</strong>时，预测问题便成为分类问题</li>
<li><strong>输入变量$X$可以是离散的，也可以是连续的</strong></li>
<li>监督学习从数据中学习一个分类模型或分类决策函数，称为<strong>分类器（classifier）</strong></li>
<li><p>分类器对新的输入进行输出的<strong>预测（prediction）</strong>，称为<strong>分类（classfication）</strong></p>
<ul>
<li>可能的输出称为<strong>类（class）</strong></li>
<li>分类的类别为多个时，称为多类分类问题</li>
</ul>
</li>
<li><p>分类问题包括学习和分类两个过程</p>
<ul>
<li>学习过程中，根据已知的训练数据集利用有效的学习方法学习一个分类器</li>
<li>分类过程中，利用学习的分类器对新的输入实例进行分类</li>
</ul>
</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/UPDF_rukv9K8KNy.png" alt="UPDF_rukv9K8KNy"></p>
<ul>
<li><p>评价分类器性能的指标一般是 <strong>分类准确率（accuracy）</strong></p>
<ul>
<li>定义：对于给定的测试数据集，分类器正确分类的样本数与总样本数之比</li>
</ul>
</li>
<li><p>对于二类分类问题常用的评价指标是<strong>精确率（precision）与召回率（recall）</strong></p>
<ul>
<li><p>通常以关注的类为正类，其他类为负类，分布器在测试数据集上的预测或正确或不正确</p>
</li>
<li><p>4种情况：</p>
<ul>
<li>TP：将正类预测为正类数</li>
<li>FN：将正类预测为负类数</li>
<li>FP：将负类预测为正类数</li>
<li>TN：将负类预测为负类数</li>
</ul>
</li>
<li><p>精确率：</p>
<script type="math/tex; mode=display">
P = \frac{TP}{TP+FP}</script></li>
</ul>
</li>
</ul>
<ul>
<li><p>召回率：</p>
<script type="math/tex; mode=display">
R = \frac{TP}{TP+FN}</script></li>
<li><p>$F_1$值：是精确率和召回率的调和均值</p>
<script type="math/tex; mode=display">
\frac{2}{F_1} = \frac{1}{P} + \frac{1}{R}</script><p>精确率和召回率都高时，$F_1$值也会高</p>
</li>
</ul>
<h2><span id="19-标注问题">1.9 标注问题</span></h2><blockquote>
<p>标注（tagging）是一个监督学习问题，可认为是分类问题的一个推广，它又是更复杂的结构预测（structure prediction）问题的简单形式</p>
</blockquote>
<ul>
<li>标注问题的输入是一个观测序列，输出是一个标记序列或状态序列</li>
<li>目标：学习一个模型，使它能够对观测序列给出标记序列作为预测<ul>
<li>可能的标记个数是有限的，但其组合所成的标记序列的个数是依序列长度呈指数级增长的</li>
</ul>
</li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/04/10/Linux4/" rel="prev" title="Linux4">
      <i class="fa fa-chevron-left"></i> Linux4
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/04/13/64%E4%BD%8D%E7%B3%BB%E7%BB%9F--GNU_C/" rel="next" title="64位系统--GNU_C">
      64位系统--GNU_C <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="GuoYB"
      src="/images/avatar1.gif">
  <p class="site-author-name" itemprop="name">GuoYB</p>
  <div class="site-description" itemprop="description">欢迎欢迎</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">103</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Ye2222" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Ye2222" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:12554804@qq.com" title="E-Mail → mailto:12554804@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">GuoYB</span>
</div><script color="0,0,255" opacity="0.5" zIndex="-1" count="99" src="https://fastly.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js"></script>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
