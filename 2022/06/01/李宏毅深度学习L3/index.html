

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="GuoYB">
  <meta name="keywords" content="">
  
    <meta name="description" content="卷积神经网络(CNN)，自注意力(Self-attention)机制，循环神经网络(RNN)，Transfomer">
<meta property="og:type" content="article">
<meta property="og:title" content="李宏毅深度学习L3">
<meta property="og:url" content="https://ye2222.github.io/2022/06/01/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0L3/index.html">
<meta property="og:site_name" content="Yeの博客">
<meta property="og:description" content="卷积神经网络(CNN)，自注意力(Self-attention)机制，循环神经网络(RNN)，Transfomer">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202205252103858.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202205252104016.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202205252104884.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202205252105684.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202205252105098.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202205252106259.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202205252115474.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202205252103648.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202205252122120.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011540275.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011554197.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011557435.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011559173.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011602332.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011606741.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011609590.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011609029.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011610577.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121530986.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121529997.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121531532.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121532801.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121547500.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121559818.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121604746.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121927804.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121933005.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121935566.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206150959111.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151009677.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151011308.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151014571.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151015496.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151016619.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151022522.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151026948.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151029985.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151030015.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151034669.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151035798.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151308161.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011932332.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011936886.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011933411.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011939047.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011942420.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011941403.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011942658.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011946215.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012006615.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012007564.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012008036.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012010332.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012012018.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012013572.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012015446.png">
<meta property="og:image" content="c:/Users/12554/AppData/Roaming/Typora/typora-user-images/image-20220601201612541.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012016199.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012018858.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012027497.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012031288.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012043669.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012047516.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012102106.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012103414.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012104168.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201016079.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201020094.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201021238.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201021586.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201023469.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201026730.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201027152.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201031355.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201031877.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201038711.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201036338.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201042918.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201043748.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201044384.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201057230.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201416702.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201421768.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201422724.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201437245.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201441878.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201450843.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201453733.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201508376.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201501785.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151319663.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151320098.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151328102.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151330114.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151341781.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151353367.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151355615.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151415355.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151435498.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151436784.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151443520.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151446205.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151453211.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151457166.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151458612.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151500280.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151505401.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151506681.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151608002.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206191607097.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206191609388.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206191622844.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206191639053.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206191640161.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206191642452.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206191816815.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206191836293.png">
<meta property="og:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206191837325.png">
<meta property="article:published_time" content="2022-06-01T07:23:07.000Z">
<meta property="article:modified_time" content="2023-04-26T06:21:34.098Z">
<meta property="article:author" content="GuoYB">
<meta property="article:tag" content="DeepLearning">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202205252103858.png">
  
  
  
  <title>李宏毅深度学习L3 - Yeの博客</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"ye2222.github.io","root":"/","version":"1.9.4","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  

  

  



  
<meta name="generator" content="Hexo 6.0.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Yeの博客</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="李宏毅深度学习L3"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-06-01 15:23" pubdate>
          2022年6月1日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          8.6k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          72 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">李宏毅深度学习L3</h1>
            
            
              <div class="markdown-body">
                
                <h2 id="convolutional-neural-network-cnn">Convolutional Neural Network
（CNN）</h2>
<ul>
<li>CNN，即卷积神经网络，主要适用于图片处理</li>
</ul>
<h3 id="图片分类">图片分类</h3>
<ul>
<li>假设我们现在有一张彩色的图片，在电脑中它有<strong>红绿蓝</strong>三个通道，每个通道是一个100*100的矩阵</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202205252103858.png" srcset="/img/loading.gif" lazyload  style="zoom:67%;" /></p>
<ul>
<li>但是对于图片来说，如果我们使用全连接层的模型，参数会变得特别多</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202205252104016.png" srcset="/img/loading.gif" lazyload  style="zoom:67%;" /></p>
<h3 id="感受野">感受野</h3>
<ul>
<li>我们观察到对于图像分类来说，要抓住的是图像中物体的特征，需要去捕捉图片的<strong>局部信息</strong>
<ul>
<li>如图中鸟的特征：鸟喙、眼睛、鸟爪</li>
</ul></li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202205252104884.png" srcset="/img/loading.gif" lazyload  style="zoom:67%;" /></p>
<ul>
<li>所以我们设置一个<strong>感受野(Receptive
field)</strong>区域，来提取这一区域覆盖的图片信息(局部信息)，并将信息给予一个神经元
<ul>
<li><strong>kernel size</strong>(感受野或者叫卷积核的大小)：<span
class="math inline">\(n \times n\)</span>，一般为<span
class="math inline">\(3\times3\)</span></li>
<li>区域可以重叠</li>
<li><strong>stride</strong>：移动感受野到图片的下一个区域的跨步</li>
<li><strong>padding</strong>：当感受野来到图片边界，剩下区域不够大时的填充</li>
<li>常规设置：每一个感受野有一组神经元（例如64个神经元）</li>
</ul></li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202205252105684.png" srcset="/img/loading.gif" lazyload  style="zoom:67%;" /></p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202205252105098.png" srcset="/img/loading.gif" lazyload  style="zoom:67%;" /></p>
<h5 id="相同特征在不同区域">相同特征在不同区域</h5>
<ul>
<li><p>给我们两张鸟的图片，它们都有鸟喙，但是它们的鸟喙在图片上的不同区域上，那对于每一个感受野来说，都需要配置一个专门的鸟喙检测的神经元吗？</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202205252106259.png" srcset="/img/loading.gif" lazyload  style="zoom:67%;" /></p></li>
<li><p>可以让所有感受野中相应的神经元来共享参数</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202205252115474.png" srcset="/img/loading.gif" lazyload  style="zoom:67%;" /></p></li>
</ul>
<h5 id="好处">好处</h5>
<ul>
<li>可以很好地处理图片
<ul>
<li>在图片中，一些重要的pattern比整张图片要小得多</li>
<li>在不同的图片中，相同的pattern会出现在图片的不同区域</li>
</ul></li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202205252103648.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h3 id="卷积层">卷积层</h3>
<ul>
<li>彩色：3个通道</li>
<li>黑白/灰：1个通道</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202205252122120.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p>假设我们的通道为1，现在我们拥有一张6*6图片，在给定的filter中，它们的值是不确定的，需要训练得到</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011540275.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p>进行卷积操作后得到的数据的结构</p>
<ul>
<li><p>列数： <span class="math display">\[
(c - c_f + 1 + padding*2)\ / \ stride
\]</span></p></li>
<li><p>行数： <span class="math display">\[
(r - r_f + 1 + padding * 2)\  / \ stride
\]</span></p></li>
<li><p>其中，</p>
<ul>
<li><p><span class="math inline">\(c\)</span>:
当前输入矩阵的列数</p></li>
<li><p><span class="math inline">\(c_f\)</span>: filter的列数</p></li>
<li><p><span class="math inline">\(r\)</span>:
当前输入矩阵的行数</p></li>
<li><p><span class="math inline">\(r_f\)</span>: filter的行数</p></li>
<li><p>padding: 指在输入矩阵外圈填充的圈数</p></li>
<li><p>stride: 指filter在移动时跨越的步数</p></li>
</ul></li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011554197.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011557435.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p>当所有的filter都对输入进行处理后，我们便获得了<strong>Feature
Map</strong>，每一个filter都是对图片的不同解读，即拓展了查看图片的角度</p>
<ul>
<li>我们可以将Feature Map投入到下一个卷积层中</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011559173.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h3 id="感受野和滤波器的比较">感受野和滤波器的比较</h3>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011602332.png" srcset="/img/loading.gif" lazyload  style="zoom:67%;" /></p>
<ul>
<li>拥有不同感受野的神经元会共享相同的参数</li>
<li>每个滤波器会在整张输入图片上进行卷积操作</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011606741.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h3 id="pooling">Pooling</h3>
<p>对像素进行子采样不会更改对象</p>
<ul>
<li>子采样是一种选取原始数据的子集的方法，用来减小数据的大小</li>
<li>子采样会改变数据集的拓扑，当某些部分没有被选取时，会留下拓扑上的洞</li>
</ul>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011608798.png" srcset="/img/loading.gif" lazyload /></p>
<h4 id="max-pooling">Max Pooling</h4>
<p>选取Filter中最大的值作为感受野的取值</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011609590.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011609029.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011610577.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h3 id="小结">小结</h3>
<ul>
<li>CNN能够捕捉局部信息，当使用CNN时，我们应该考虑我们的数据集和目标，是否适用CNN
<ul>
<li>例如Alpha
Go中，在围棋中，我们需要去考虑局部的信息，而且在这种具体的情况中，pooling并不适用，子采样会损失围棋分布的信息</li>
</ul></li>
<li>CNN在图像的放缩和旋转后，不能够正常的识别，需要我们进行数据增强(data
augmentation)</li>
</ul>
<h2 id="recurent-neural-networkrnn">Recurent Neural Network(RNN)</h2>
<h3 id="slot-filling">Slot Filling</h3>
<ul>
<li>输入一段语句，给出填空的答案</li>
</ul>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121525234.png" srcset="/img/loading.gif" lazyload /></p>
<ul>
<li>可不可以使用前向网络(Feedforward network)来实现
<ul>
<li>输入单词（使用单词编码），每一个单词用一个向量来表示</li>
<li>输出单词属于某一个空的概率</li>
</ul></li>
</ul>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121537487.png" srcset="/img/loading.gif" lazyload /></p>
<ul>
<li>问题：网络无法结合上下单词，理解词汇的意义，如到达和离开的区别，只能捕捉到目的地单词
<ul>
<li>我们需要网络具有记忆的功能，能够记住前后的单词</li>
</ul></li>
</ul>
<h4 id="单词编码">单词编码</h4>
<h5 id="of-n-encoding">1-of-N encoding</h5>
<ul>
<li>向量长度为整个词库的词语数量</li>
<li>一个维度标记词库中的一个单词</li>
<li>对于某一个单词，它所在维度为1，其他维度为0</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121530986.png" srcset="/img/loading.gif" lazyload  style="zoom:67%;" /></p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121529997.png" srcset="/img/loading.gif" lazyload  style="zoom:67%;" /></p>
<h5 id="改进">改进</h5>
<h6 id="others">Others</h6>
<ul>
<li>将其他不存在词库中的单词设置为“other”</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121531532.png" srcset="/img/loading.gif" lazyload  style="zoom:67%;" /></p>
<h6 id="word-hashing">Word hashing</h6>
<ul>
<li>维度用来标记字母组合</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121532801.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h3 id="rnn">RNN</h3>
<h4 id="存储前一个输入的信息">存储前一个输入的信息</h4>
<ul>
<li>将隐藏层的信息存储起来，将该信息作为输入，让网络可以学习</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121547500.png" srcset="/img/loading.gif" lazyload  style="zoom:67%;" /></p>
<h5 id="例子">例子</h5>
<ul>
<li><p>假设所有的权重为1，没有bias，激活函数都是线性的</p></li>
<li><p>输入序列： <span class="math display">\[
\begin{equation}
  \begin{bmatrix}
  1 \\
  1
  \end{bmatrix}
  \begin{bmatrix}
  1 \\
  1
  \end{bmatrix}
  \begin{bmatrix}
  2 \\
  2
  \end{bmatrix}
\end{equation}
\]</span></p></li>
<li><p>初始的存储值为0</p></li>
</ul>
<p>第一次输入: <span class="math display">\[
\begin{bmatrix}
    1 \\
    1
\end{bmatrix}
\]</span> <img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121554397.png" srcset="/img/loading.gif" lazyload /></p>
<ul>
<li><p>两个存储值都会变为2</p></li>
<li><p>输出为 <span class="math display">\[
\begin{bmatrix}
  4 \\
  4
\end{bmatrix}
\]</span></p></li>
</ul>
<p>第二次输入： <span class="math display">\[
\begin{bmatrix}
    1 \\
    1
\end{bmatrix}
\]</span> <img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121557234.png" srcset="/img/loading.gif" lazyload /></p>
<ul>
<li>两个存储值会变为6</li>
<li>输出为</li>
</ul>
<p><span class="math display">\[
\begin{bmatrix}
    12 \\
    12
\end{bmatrix}
\]</span></p>
<h5 id="小结-1">小结</h5>
<ul>
<li>改变输入序列的顺序，会改变输出</li>
<li>反复使用这样的结构</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121559818.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p>如上图所示，当前输入，可以获得前一个输入的信息，可以简单区分出一些不同</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121604746.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<ul>
<li>可以将网络做深</li>
</ul>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121605857.png" srcset="/img/loading.gif" lazyload /></p>
<h5 id="类别">类别</h5>
<ul>
<li>Elman Network：传递前一个输入的隐藏层信息</li>
<li>Jordan Network：传递前一个输出的信息</li>
</ul>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121607014.png" srcset="/img/loading.gif" lazyload /></p>
<h4 id="双向rnn">双向RNN</h4>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121608475.png" srcset="/img/loading.gif" lazyload /></p>
<p>将前向输入和逆向输入相同位置上的隐藏信息拼合到一个，存储当前单词前后的信息</p>
<h4 id="lstm">LSTM</h4>
<h5 id="结构">结构</h5>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121617309.png" srcset="/img/loading.gif" lazyload /></p>
<ul>
<li><p>由4个部分组成</p>
<ul>
<li>Input Gate：由信号控制是否接收输入</li>
<li>Memory Cell：存储记忆的信息</li>
<li>Forget Gate：由信号控制是否清除现在存储的信息</li>
<li>Output Gate：由信号控制是否输出</li>
</ul></li>
<li><p>一共有4个输入，1个输出</p>
<ul>
<li>输入：3个signal，1个正常输入</li>
</ul></li>
</ul>
<h5 id="计算过程">计算过程</h5>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121626766.png" srcset="/img/loading.gif" lazyload /></p>
<ul>
<li>激活函数f输出为0到1，可以用来控制是否接收信息</li>
<li>输入<span class="math inline">\(z\)</span>和<span
class="math inline">\(z_i\)</span>，经过激活函数得到<span
class="math inline">\(g(z)\)</span>和<span
class="math inline">\(f(z_i)\)</span>，将两者相乘，即为<span
class="math inline">\(g(z)f(z_i)\)</span>
<ul>
<li>这一步用来控制输入</li>
</ul></li>
<li>输入<span class="math inline">\(z_f\)</span>，经过激活函数得到<span
class="math inline">\(f(z_f)\)</span>，与Memory
Cell中存储的信息c进行相乘，即为<span
class="math inline">\(cf(z_f)\)</span>
<ul>
<li>这一步用来控制是否要清楚当前信息c</li>
</ul></li>
<li>将前两步获得的数据相加获得新的存储信息<span
class="math inline">\(c^\prime\)</span></li>
</ul>
<p><span class="math display">\[
c^\prime = g(z)f(z_i) + cf(z_f)
\]</span></p>
<ul>
<li><p>输入<span class="math inline">\(c^\prime\)</span>和<span
class="math inline">\(z_o\)</span>，经过激活函数得到<span
class="math inline">\(h(c^\prime)\)</span>和<span
class="math inline">\(f(z_o)\)</span>，将两者相乘，得到输出a，即 <span
class="math display">\[
a = h(c^\prime)f(z_0)
\]</span></p>
<ul>
<li>这一步用来控制输出</li>
</ul></li>
</ul>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121852288.png" srcset="/img/loading.gif" lazyload /></p>
<p>在RNN网络架构中，一般用LSTM代替神经元</p>
<h5 id="缺点">缺点</h5>
<ul>
<li><p>参数过多</p>
<ul>
<li>每一个LSTM都需要4个输入，需要4倍的参数*LSTM数目</li>
</ul>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121908775.png" srcset="/img/loading.gif" lazyload /></p>
<ul>
<li>解决方案：利用当前输入，生成4个向量，所有的LSTM使用对应位置上的同一向量</li>
</ul>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121918618.png" srcset="/img/loading.gif" lazyload /></p>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121921657.png" srcset="/img/loading.gif" lazyload /></p>
<ul>
<li>可以将上一个LSTM网络中的c拼合输入中</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121927804.png" srcset="/img/loading.gif" lazyload  style="zoom: 80%;" /></p></li>
</ul>
<h5 id="多层lstm">多层LSTM</h5>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121933005.png" srcset="/img/loading.gif" lazyload  style="zoom: 67%;" /></p>
<h5 id="学习目标">学习目标</h5>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121935566.png" srcset="/img/loading.gif" lazyload  style="zoom:67%;" /></p>
<ul>
<li>BPTT（Backpropagation through time）</li>
</ul>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121937184.png" srcset="/img/loading.gif" lazyload /></p>
<h4 id="rnn训练较为困难">RNN训练较为困难</h4>
<ul>
<li>RNN参数的损失曲面十分陡峭</li>
<li>可以采用clip，剪切掉超过某一范围的参数，强制在一定范围内</li>
</ul>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121939602.png" srcset="/img/loading.gif" lazyload /></p>
<ul>
<li>损失曲面会抖动严重的原因</li>
</ul>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121943377.png" srcset="/img/loading.gif" lazyload /></p>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121945280.png" srcset="/img/loading.gif" lazyload /></p>
<p>参数的细微改变，会导致后面的输出发生巨大变化（梯度爆炸），或者一直为0（梯度消失），学习率无法调节</p>
<h4 id="lstm的优势">LSTM的优势</h4>
<ul>
<li>可以解决梯度消失的问题（不是梯度爆炸）
<ul>
<li>fotget gate关闭可以消除前面记录信息的影响，摆脱梯度消失</li>
</ul></li>
<li>记录的信息和输入可以拼合</li>
</ul>
<h4 id="rnn的应用场景">RNN的应用场景</h4>
<h5 id="many-to-one">Many to one</h5>
<h6 id="sentiment-analysis">Sentiment Analysis</h6>
<ul>
<li>语句分析，将其分类</li>
<li>输入：向量序列</li>
<li>输出：向量标签</li>
</ul>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206121957183.png" srcset="/img/loading.gif" lazyload /></p>
<h6 id="key-term-extraction">Key Term Extraction</h6>
<ul>
<li>关键词的提取</li>
<li>输入：向量序列</li>
<li>输出：一个向量</li>
</ul>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206122000086.png" srcset="/img/loading.gif" lazyload /></p>
<h5 id="many-to-many输出序列较短">Many to Many（输出序列较短）</h5>
<p>输入和输出都是序列，输出序列较短</p>
<h6 id="speech-recognition">Speech Recognition</h6>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206122005975.png" srcset="/img/loading.gif" lazyload /></p>
<p>好棒棒这种叠词，可能无法识别</p>
<p>Connectionist Temporal Classification (CTC)</p>
<ul>
<li>加入了额外的符号<span
class="math inline">\(\phi\)</span>来代表空</li>
</ul>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206122008246.png" srcset="/img/loading.gif" lazyload /></p>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206122010241.png" srcset="/img/loading.gif" lazyload /></p>
<ul>
<li>CTC是识别每一个字母的</li>
</ul>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206122010310.png" srcset="/img/loading.gif" lazyload /></p>
<h5 id="many-to-many-没有限制">Many to Many （没有限制）</h5>
<p>输入和输出都是序列，且长度没有限制，可以不一样 -&gt; Sequence to
sequence learning</p>
<h6 id="machine-translation">Machine Translation</h6>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206150959111.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151009677.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h5 id="beyond-sequence">Beyond Sequence</h5>
<h6 id="syntactic-parsing">Syntactic parsing</h6>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151011308.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h5 id="sequence-to-sequence-auto-encoder-text">Sequence-to-sequence
Auto-encoder Text</h5>
<p>要理解一个句子的意思，单词的顺序不可以忽略</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151014571.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151015496.png" srcset="/img/loading.gif" lazyload  style="zoom: 80%;" /></p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151016619.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h5 id="sequence-to-sequence-auto-encoder-speech">Sequence-to-sequence
Auto-encoder Speech</h5>
<ul>
<li>不定长度的序列的降维</li>
<li>发音相近的词语转换为向量后，会聚集在一定区域</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151022522.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p>音频归档分为可变长度的音频段，然后可以对语音进行检索</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151026948.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p>将语音片段转换为向量后，我们希望向量能够表示这个语音片段</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151029985.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p>Encoder和Decoder是联合训练的</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151030015.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h4 id="attention-based-model">Attention-based Model</h4>
<ul>
<li>DNN/RNN可以通过Reading Head
Controller在Memory中找到自己想要的相关信息</li>
<li>就像人类的大脑一样，可以去记忆中去搜索相关的知识</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151034669.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<ul>
<li>DNN/RNN同时也可以写入Memory</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151035798.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h5 id="应用">应用</h5>
<h6 id="reading-comprehension">Reading Comprehension</h6>
<ul>
<li>对文本进行语义分析，每一个句子转换为一个向量</li>
<li>DNN/RNN读取向量信息</li>
</ul>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151242792.png" srcset="/img/loading.gif" lazyload /></p>
<h6 id="visual-question-answering">Visual Question Answering</h6>
<ul>
<li>输入一张图片和一个问题，输出问题的答案</li>
</ul>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151244411.png" srcset="/img/loading.gif" lazyload /></p>
<ul>
<li>利用CNN将图片的每一个区域转换为一个向量</li>
</ul>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151245876.png" srcset="/img/loading.gif" lazyload /></p>
<h6 id="speech-question-answering">Speech Question Answering</h6>
<p>听力考试</p>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151251480.png" srcset="/img/loading.gif" lazyload /></p>
<h4 id="rnn和structured-learning的比较">RNN和Structured
Learning的比较</h4>
<p>RNN，LSTM</p>
<ul>
<li>非双向的RNN不能够考虑整个序列</li>
<li>Cost和eroor总是相关的</li>
<li>deep</li>
</ul>
<p>HMM，CRF，Structured Perceptron/SVM</p>
<ul>
<li>使用了Viterbi，考虑了整个序列
<ul>
<li>但双向的RNN也可考虑</li>
</ul></li>
<li>可以明确考虑标签依赖关系</li>
<li>Cost是error的下界</li>
</ul>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151300653.png" srcset="/img/loading.gif" lazyload /></p>
<h5 id="一起使用">一起使用</h5>
<h6 id="speech-recognition-cnnlstmdnn-hmm">Speech Recognition:
CNN/LSTM/DNN + HMM</h6>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151308161.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h6 id="semantic-tagging-bi-directional-lstm-crfstructured-svm">Semantic
Tagging: Bi-directional LSTM + CRF/Structured SVM</h6>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151310882.png" srcset="/img/loading.gif" lazyload /></p>
<h2 id="self-attention">Self-Attention</h2>
<h4 id="输入">输入</h4>
<ul>
<li>输入是一个向量，经过模型后输出一个数字或者类别</li>
<li>输入时一组向量，经过模型后输出一组数字或者类别</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011932332.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p><strong>输入时是一组向量</strong></p>
<ul>
<li>语句</li>
<li>语音</li>
<li>图（如关系图）</li>
</ul>
<p><strong>语句</strong></p>
<p>如一句话“this is a
cat”，我们需要对数据集进行编码处理，以便识别各个单词</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011936886.png" srcset="/img/loading.gif" lazyload  style="zoom:50%;" /></p>
<ul>
<li>One-hot Encoding 一键编码
<ul>
<li>有多少个单词，就构建一个多长的向量</li>
<li>这样做的后果是模型不知道单词之间的关系，它们是割裂的</li>
</ul></li>
<li>Word Embedding 词嵌入
<ul>
<li>对词语进行编码处理，相似意义的词会聚集</li>
</ul></li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011933411.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p><strong>语音</strong></p>
<p>进行加窗处理</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011939047.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p><strong>图</strong></p>
<p>将每一个节点都视为一个向量</p>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011940622.png" srcset="/img/loading.gif" lazyload /></p>
<h4 id="输出">输出</h4>
<ul>
<li>每一个向量都有一个标签</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011942420.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p>例子</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011941403.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<ul>
<li>整个序列有一个标签</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011942658.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p>例子</p>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011943264.png" srcset="/img/loading.gif" lazyload /></p>
<ul>
<li>模型自己决定有多少个标签（seq2seq）</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206011946215.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h4 id="思考">思考</h4>
<ul>
<li>对于一段文本，我们需要考虑前后文，如判断"I saw a
saw"中各个单词的词性
<ul>
<li>对于前后文问题，我们可以将一个窗口内的单词都输入一个全连接层中，但是这样较前面的和较后面的很难一起考虑</li>
<li>考虑整个句子，可以将整个句子丢入一个全连接层中，但是这样模型会变得很复杂</li>
</ul></li>
</ul>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012004752.png" srcset="/img/loading.gif" lazyload /></p>
<ul>
<li>可以使用自注意力机制</li>
</ul>
<h3 id="自注意力">自注意力</h3>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012006615.png" srcset="/img/loading.gif" lazyload  style="zoom: 67%;" /></p>
<h4 id="实现">实现</h4>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012007564.png" srcset="/img/loading.gif" lazyload  style="zoom: 67%;" /></p>
<h5
id="考虑当前向量和序列中其他向量的关系">考虑当前向量和序列中其他向量的关系</h5>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012008036.png" srcset="/img/loading.gif" lazyload  style="zoom:67%;" /></p>
<h5
id="可以对两个要关联的向量进行某种运算">可以对两个要关联的向量进行某种运算</h5>
<ul>
<li><strong>Dot-product</strong></li>
<li>Additive</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012010332.png" srcset="/img/loading.gif" lazyload  style="zoom:67%;" /></p>
<p>对于当前向量，计算出一个query向量，对于其他的向量，各有一个key向量，可以分别计算得出注意力分数(attention
score)</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012012018.png" srcset="/img/loading.gif" lazyload  style="zoom: 67%;" /></p>
<p>可以对注意力分数(attention score)进行softmax运算</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012013572.png" srcset="/img/loading.gif" lazyload  style="zoom:50%;" /></p>
<p>然后基于注意力分数(attention score)，利用value向量，提取出信息</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012015446.png" srcset="/img/loading.gif" lazyload  style="zoom:50%;" /></p>
<p>对于所有的向量，平行地进行运算</p>
<p><img src="C:/Users/12554/AppData/Roaming/Typora/typora-user-images/image-20220601201612541.png" srcset="/img/loading.gif" lazyload  style="zoom:50%;" /></p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012016199.png" srcset="/img/loading.gif" lazyload  style="zoom:67%;" /></p>
<h5
id="对于这样相同的运算我们可以将这些向量拼合成矩阵进行矩阵运算加快运算">对于这样相同的运算，我们可以将这些向量拼合成矩阵，进行矩阵运算，加快运算</h5>
<ul>
<li>q，k，v的获取
<ul>
<li>query：<span class="math inline">\(Q = W^q I\)</span></li>
<li>key：<span class="math inline">\(K = W^k I\)</span></li>
<li>value：<span class="math inline">\(V = W^vI\)</span></li>
</ul></li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012018858.png" srcset="/img/loading.gif" lazyload  style="zoom: 80%;" /></p>
<ul>
<li>注意力分数的获取</li>
</ul>
<p><span class="math display">\[
A = K^T  Q \\
A \mathop\rightarrow^{softmax} A^`
\]</span></p>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012020665.png" srcset="/img/loading.gif" lazyload /></p>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012024761.png" srcset="/img/loading.gif" lazyload /></p>
<ul>
<li>信息的获取</li>
</ul>
<p><span class="math display">\[
O = V A^`
\]</span></p>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012026689.png" srcset="/img/loading.gif" lazyload /></p>
<ul>
<li>小结</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012027497.png" srcset="/img/loading.gif" lazyload  style="zoom:67%;" /></p>
<h3 id="multi-head-self-attention">Multi-head Self-attention</h3>
<ul>
<li>多头注意力机制</li>
<li>可以探索不同类型之间的联系</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012031288.png" srcset="/img/loading.gif" lazyload  style="zoom: 67%;" /></p>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012032401.png" srcset="/img/loading.gif" lazyload /></p>
<h3 id="positional-encoding">Positional Encoding</h3>
<ul>
<li>在注意力机制中，序列输入后，模型没有对于位置的信息，不同距离的两个向量对于模型来说是一样的</li>
<li>我们可以在向量中加入位置信息，每一个位置有一个独一无二的向量<span
class="math inline">\(e^i\)</span>
<ul>
<li>手工制作</li>
<li>从数据中学习</li>
</ul></li>
</ul>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012039598.png" srcset="/img/loading.gif" lazyload /></p>
<h3 id="自注意力的应用">自注意力的应用</h3>
<ul>
<li><p>NLP 自然语言处理</p></li>
<li><p>语音处理：Truncated Self-attention</p></li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012043669.png" srcset="/img/loading.gif" lazyload  style="zoom:67%;" /></p>
<ul>
<li>图像</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012047516.png" srcset="/img/loading.gif" lazyload  style="zoom: 67%;" /></p>
<ul>
<li>Self-attention GAN</li>
</ul>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012047338.png" srcset="/img/loading.gif" lazyload /></p>
<ul>
<li>DEtection Transformer(DETR)</li>
</ul>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012048033.png" srcset="/img/loading.gif" lazyload /></p>
<h3 id="self-attention和cnn的比较">Self-attention和CNN的比较</h3>
<ul>
<li>CNN是简化版的self-attention
<ul>
<li>CNN是可以只关注一个感受野的self-attention</li>
</ul></li>
<li>self-attention是复杂版的CNN
<ul>
<li>Self-attention是具有可学习感受野的CNN</li>
</ul></li>
</ul>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012100697.png" srcset="/img/loading.gif" lazyload /></p>
<ul>
<li>Self-attention适合更多的数据，而CNN适合比较少的数据</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012102106.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h3 id="self-attention和rnn的比较">Self-attention和RNN的比较</h3>
<p>RNN不可以平行处理，而自注意力可以</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012103414.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h3 id="self-attention-for-graph">Self-attention for Graph</h3>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206012104168.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h3 id="transformer">Transformer</h3>
<h4 id="seq2seq">Seq2seq</h4>
<ul>
<li>对于序列到序列的模型，我们输入一段序列，模型会输出一段序列，且输出序列的长度取决于模型
<ul>
<li>语音识别(Speech Recognition)</li>
<li>机器翻译(Machine Translation)</li>
<li>语音翻译(Speech Translation)</li>
<li>文本转语音合成器(Text-to-Speech(TTS) Synthesis)</li>
<li>Seq2seq for Chatbot</li>
</ul></li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201016079.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<ul>
<li><p>其他的一些应用</p>
<ul>
<li>Seq2seq for Syntactic Parsing</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201020094.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<ul>
<li>Seq2seq for Multi-label Classification</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201021238.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<ul>
<li>Seq2seq for Object Detection</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201021586.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p></li>
</ul>
<h4 id="transformer-1">Transformer</h4>
<p>Encoder-Decoder架构</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201023469.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p>结构</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201026730.png" srcset="/img/loading.gif" lazyload  style="zoom: 80%;" /></p>
<h5 id="encoder">Encoder</h5>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201027152.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201031355.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p>Layer Norm的调整</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201031877.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h5 id="decoder">Decoder</h5>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201038711.png" srcset="/img/loading.gif" lazyload  style="zoom: 67%;" /></p>
<p>Transformer的Decoder是一个自回归的Decoder（Autoregressive
Decoder）</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201036338.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h5 id="masked-self-attention">Masked Self-attention</h5>
<ul>
<li>在解码器中，第一个注意力机制是一个掩码的自注意力</li>
<li>这是因为解码器需要输出一个序列，它需要在不知道后面的信息的情况下，根据前面的信息，来预测当前的输出</li>
<li>所以我们在训练时，需要将后面的序列盖住</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201042918.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<ul>
<li>在训练时，我们给解码器的输入都是正确答案，帮助其完成训练</li>
</ul>
<p><strong>停止符号</strong></p>
<p>为了让输出停止，我们需要定义一个停止符号，提示解码器停止输出</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201043748.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201044384.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h5 id="nat-非自回归">NAT 非自回归</h5>
<ul>
<li>AT需要前面的输出信息，才能给出当前的输出</li>
<li>NAT可以并行地给出输出，速度比AT要快，生成更加稳定</li>
</ul>
<p>NAT解码器如何决定输出的长度</p>
<ul>
<li>预测输出序列的长度(predictor)</li>
<li>输出一个固定长度的长序列，忽略终止符END后面的Token</li>
</ul>
<h5 id="cross-attention">Cross attention</h5>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201057230.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p>Cross attention部分会将Encoder的最后一个输出转换为Decoder部分的<span
class="math inline">\(k\)</span>和<span
class="math inline">\(v\)</span>矩阵</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201416702.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201421768.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h6 id="不同的连接方式">不同的连接方式</h6>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201422724.png" srcset="/img/loading.gif" lazyload   /></p>
<h4 id="训练transformer">训练Transformer</h4>
<ul>
<li>Encoder和Decoder联合训练</li>
<li>使用softmax和cross entropy进行训练</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201437245.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h5 id="teacher-forcing模式">Teacher Forcing模式</h5>
<p>将输出数据作为Decoder的输入，使其向正确输出靠近</p>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201439938.png" srcset="/img/loading.gif" lazyload /></p>
<h4 id="tips">Tips</h4>
<h5 id="copy-machanism-复制机制">Copy Machanism 复制机制</h5>
<p>将一些不太需要翻译的人名、地名等直接复制</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201441878.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h5 id="guided-attention">Guided Attention</h5>
<ul>
<li><p>Monotonic Attention</p></li>
<li><p>Location-aware attention</p></li>
<li><p>在一些任务中，输入和输出是单调排列的，顺序关系不可改变</p></li>
<li><p>例如下面的序列中，在输出时，第一个输出中，Attention关注的是后面的序列</p></li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201450843.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h5 id="beam-search">Beam Search</h5>
<ul>
<li>在Attention
Score中，模型会选择当前分数最高的，但是多次选择后，综合起来，不一定是最好的选择</li>
<li>Beam Search会综合考虑全局的分数，选择最好的结果</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201453733.png" srcset="/img/loading.gif" lazyload  style="zoom: 80%;" /></p>
<p>但是最好的选择不一定会产生很好的结果</p>
<h5 id="sampling">Sampling</h5>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201456221.png" srcset="/img/loading.gif" lazyload /></p>
<p>在一些任务中，生成序列时，Decoder需要一些噪声(Randomness)，sample是指从某些分布中sample中出来的噪声</p>
<h6 id="scheduled-sampling">Scheduled Sampling</h6>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201508376.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p>采样由Decoder决定</p>
<h5 id="optimizing-evaluation-metrics">Optimizing Evaluation
Metrics</h5>
<p>优化方案的选择</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206201501785.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<ul>
<li>Cross Entropy</li>
<li>BLEU score</li>
<li>Reinforcement learning</li>
</ul>
<h3 id="各种各样的attention">各种各样的Attention</h3>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151319663.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h4 id="自注意力机制的运作">自注意力机制的运作</h4>
<ul>
<li>利用Query和Key构造一个Attention Matrix</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151320098.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<ul>
<li>自注意力只是一个大型网络的一个模块</li>
<li>当序列的长度N足够大的时候，自注意力在计算占主导</li>
<li>通常用于图像处理</li>
</ul>
<h4
id="人工干预来跳过一些attention-matrix的计算">人工干预来跳过一些Attention
Matrix的计算</h4>
<h5 id="local-attentiontruncated-attention">Local Attention/Truncated
Attention</h5>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151328102.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<ul>
<li>只计算标记的部位，其他位置设置为0</li>
<li>跟CNN有些相似</li>
</ul>
<h5 id="stride-attention">Stride Attention</h5>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151330114.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<ul>
<li>选中从自身向左右两边跨越规定的步数的部位，进行计算</li>
</ul>
<h5 id="global-attention">Global Attention</h5>
<ul>
<li>在原来的序列中添加special token
<ul>
<li>关注(attend)每一个token，可以收集全局信息</li>
<li>被每一个token关注(attend)，知道全局信息</li>
</ul></li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151341781.png" srcset="/img/loading.gif" lazyload  style="zoom:67%;" /></p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151353367.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p>图中前两个是special token</p>
<h5 id="小结-2">小结</h5>
<ul>
<li>可以在一个模型中同时使用不同的Attention
<ul>
<li>不同的head可以使用不同的模式</li>
</ul></li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151355615.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h4
id="关注一些matrix中关键的部分critical-parts">关注一些Matrix中关键的部分(Critical
Parts)</h4>
<ul>
<li>小数值直接设置为0</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151415355.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<ul>
<li>如何快速估计注意力权重较小的部分</li>
</ul>
<h5 id="clustering">Clustering</h5>
<ul>
<li>Reformer</li>
<li>Routing Transformer</li>
</ul>
<h6 id="步骤1">步骤1</h6>
<p>基于相似度对query和key进行聚类标注</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151435498.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h6 id="步骤2">步骤2</h6>
<ul>
<li>相同类别的才计算attention weight</li>
<li>不同类别的设置为0</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151436784.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h5 id="learnable-patterns">Learnable Patterns</h5>
<p>通过学习来获取需要计算的部位</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151443520.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h5 id="不需要完整的attention-matrix">不需要完整的Attention matrix</h5>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151446205.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<ul>
<li>可以减少key和value的长度</li>
<li>query的长度不变，因为输出长度需要不变</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151453211.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h6 id="使用卷积">使用卷积</h6>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151457166.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h6 id="使用参数矩阵相乘">使用参数矩阵相乘</h6>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151458612.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h4 id="注意力机制计算">注意力机制计算</h4>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151500280.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<ul>
<li>利用输入I获取Q、K、V进行运算，得到输出O</li>
<li>为加快运算，采用矩阵计算的形式</li>
</ul>
<h5 id="计算方式的不同">计算方式的不同</h5>
<ul>
<li><span class="math inline">\(K^TQ\)</span>先计算</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151505401.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<ul>
<li><span class="math inline">\(VK^T\)</span>先计算</li>
</ul>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151506681.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p>三个矩阵计算顺序不同，进行乘法次数不同，结果相同</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206151608002.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p>而Q、K、V三个矩阵的运算中，</p>
<p>正常进行计算，会进行<span
class="math inline">\((d+d^\prime)N^2\)</span>次乘法运算</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206191607097.png" srcset="/img/loading.gif" lazyload style="zoom:80%;" /></p>
<p>先计算<span class="math inline">\(V K^T\)</span>的话，会计算<span
class="math inline">\(2d^\prime
dN\)</span>次乘法运算，小于正常运算次数，序列长度N是大于维度d的</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206191609388.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h5 id="注意力计算的变换">注意力计算的变换</h5>
<p>我们利用当前向量的<span
class="math inline">\(q\)</span>矩阵，来与自身和其他向量的<span
class="math inline">\(k\)</span>矩阵进行运算，再经过<span
class="math inline">\(softmax\)</span>运算，得到<span
class="math inline">\(\alpha^{\prime}\)</span>，即 <span
class="math display">\[
\alpha^{\prime}_{1,i} = \sum_{i=1}^{N}\frac{exp(q^1\cdot
k^i)}{\sum^N_{j=1}exp(q^1\cdot k^j)}
\]</span> 这里以<span class="math inline">\(a^1\)</span>向量(<span
class="math inline">\(q^1\)</span>矩阵)为当前向量。</p>
<p>再将得到的<span
class="math inline">\(\alpha^{\prime}\)</span>与对应的<span
class="math inline">\(v\)</span>矩阵进行运算，合成起来得到<span
class="math inline">\(b^1\)</span>，即 <span class="math display">\[
b^1 = \sum_{i=1}^{N}\alpha^{\prime}_{1,i}v^i =
\sum_{i=1}^{N}\frac{exp(q^1\cdot k^i)}{\sum^N_{j=1}exp(q^1\cdot k^j)}v^i
\]</span>
<img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206191622844.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p>在这里，我们可以对<span
class="math inline">\(softmax\)</span>的计算进行改变 <span
class="math display">\[
exp(q\cdot k) \approx \phi(q) \cdot \phi(k)
\]</span> 这里的<span
class="math inline">\(\phi\)</span>是一个变换，那么<span
class="math inline">\(b\)</span>的计算可以变换为 <span
class="math display">\[
\begin{equation}
\begin{aligned}
b^1 = \sum_{i=1}^{N}\alpha^{\prime}_{1,i}v^i
&amp;=\sum_{i=1}^{N}\frac{exp(q^1\cdot k^i)}{\sum^N_{j=1}exp(q^1\cdot
k^j)}v^i \\ \\
&amp;=
\sum^N_{i=1}\frac{\phi(q^1)\cdot\phi(k^i)}{\sum^N_{j=1}\phi(q^1)\cdot\phi(k^j)}v^i
\\ \\
&amp;=
\frac{\sum^N_{i=1}\phi(q^1)\cdot\phi(k^i)v^i}{\sum^N_{j=1}\phi(q^1)\cdot\phi(k^j)}
\end{aligned}
\end{equation}
\]</span> 而分母项可以进一步进行调整 <span class="math display">\[
\begin{equation}
\sum^N_{j=1}\phi(q^1)\cdot\phi(k^j) = \phi(q^1)
\cdot\sum^{N}_{j=1}\phi(k^j)
\end{equation}
\]</span>
<img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206191639053.png" srcset="/img/loading.gif" lazyload  style="zoom:67%;" /></p>
<p>那么<span class="math inline">\(b^1\)</span>的计算进一步调整</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206191640161.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p>我们可以利用<span class="math inline">\(k\)</span>和<span
class="math inline">\(v\)</span>提前计算好部分值，需要时直接调用即可</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206191642452.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206191816815.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<p>这样子，有一部分不用重复进行计算</p>
<p><img
src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206191819653.png" srcset="/img/loading.gif" lazyload /></p>
<p>这样利用<span class="math inline">\(\phi(k)\)</span>和<span
class="math inline">\(v\)</span>计算出来的M组向量相当于有M组模板，<span
class="math inline">\(\phi(q)\)</span>与之相乘是在进行选择。</p>
<h4 id="通过学习来构造attention-matrix">通过学习来构造Attention
Matrix</h4>
<p>注意力机制通过<span class="math inline">\(q\)</span>和<span
class="math inline">\(k\)</span>来计算Attention
Matrix，但是我们可以将整个矩阵是为网络的参数</p>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206191836293.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>
<h4 id="小结-3">小结</h4>
<p><img src="https://fastly.jsdelivr.net/gh/Ye2222/blogImage@main/images2/202206191837325.png" srcset="/img/loading.gif" lazyload  style="zoom:80%;" /></p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="category-chain-item">深度学习</a>
  
  
    <span>></span>
    
  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/" class="category-chain-item">李宏毅</a>
  
  

  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/DeepLearning/">#DeepLearning</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>李宏毅深度学习L3</div>
      <div>https://ye2222.github.io/2022/06/01/李宏毅深度学习L3/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>GuoYB</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2022年6月1日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/06/14/%E8%B6%A3%E8%B0%88Linux1/" title="趣谈Linux1">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">趣谈Linux1</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/05/30/originL4-LabTalk/" title="originL4-LabTalk">
                        <span class="hidden-mobile">originL4-LabTalk</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</body>
</html>
